{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c17115ec",
   "metadata": {},
   "source": [
    "# Ivan Zepeda\n",
    "c0883949\n",
    "\n",
    "# In Class assignment and inclass activity\n",
    "\n",
    ">https://www.youtube.com/watch?v=0yaYwDyBxFA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac99f7c3",
   "metadata": {},
   "source": [
    "## Apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11d4ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = [['Milk', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "['Dill', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "['Milk', 'Apple', 'Kidney Beans', 'Eggs'],\n",
    "['Milk', 'Unicorn', 'Corn', 'Kidney Beans', 'Yogurt'], \n",
    "['Corn' 'Onion', 'Onion', 'Kidney Beans', 'Ice cream', 'Eggs']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6968c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(dataset).transform(dataset)\n",
    "\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0d6b2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>(Eggs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Milk)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Onion)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Yogurt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>(Kidney Beans, Eggs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Eggs, Onion)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Kidney Beans, Milk)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Kidney Beans, Onion)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Kidney Beans, Yogurt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Kidney Beans, Eggs, Onion)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support                     itemsets\n",
       "0       0.8                       (Eggs)\n",
       "1       1.0               (Kidney Beans)\n",
       "2       0.6                       (Milk)\n",
       "3       0.6                      (Onion)\n",
       "4       0.6                     (Yogurt)\n",
       "5       0.8         (Kidney Beans, Eggs)\n",
       "6       0.6                (Eggs, Onion)\n",
       "7       0.6         (Kidney Beans, Milk)\n",
       "8       0.6        (Kidney Beans, Onion)\n",
       "9       0.6       (Kidney Beans, Yogurt)\n",
       "10      0.6  (Kidney Beans, Eggs, Onion)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "frequent_itemsets = apriori(df, min_support=0.6, use_colnames=True)\n",
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dd73683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>(Onion)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Onion)</td>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Milk)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Onion)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Yogurt)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Kidney Beans, Eggs)</td>\n",
       "      <td>(Onion)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Kidney Beans, Onion)</td>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Eggs, Onion)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>(Kidney Beans, Onion)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(Onion)</td>\n",
       "      <td>(Kidney Beans, Eggs)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              antecedents            consequents  antecedent support  \\\n",
       "0          (Kidney Beans)                 (Eggs)                 1.0   \n",
       "1                  (Eggs)         (Kidney Beans)                 0.8   \n",
       "2                  (Eggs)                (Onion)                 0.8   \n",
       "3                 (Onion)                 (Eggs)                 0.6   \n",
       "4                  (Milk)         (Kidney Beans)                 0.6   \n",
       "5                 (Onion)         (Kidney Beans)                 0.6   \n",
       "6                (Yogurt)         (Kidney Beans)                 0.6   \n",
       "7    (Kidney Beans, Eggs)                (Onion)                 0.8   \n",
       "8   (Kidney Beans, Onion)                 (Eggs)                 0.6   \n",
       "9           (Eggs, Onion)         (Kidney Beans)                 0.6   \n",
       "10                 (Eggs)  (Kidney Beans, Onion)                 0.8   \n",
       "11                (Onion)   (Kidney Beans, Eggs)                 0.6   \n",
       "\n",
       "    consequent support  support  confidence  lift  leverage  conviction  \\\n",
       "0                  0.8      0.8        0.80  1.00      0.00         1.0   \n",
       "1                  1.0      0.8        1.00  1.00      0.00         inf   \n",
       "2                  0.6      0.6        0.75  1.25      0.12         1.6   \n",
       "3                  0.8      0.6        1.00  1.25      0.12         inf   \n",
       "4                  1.0      0.6        1.00  1.00      0.00         inf   \n",
       "5                  1.0      0.6        1.00  1.00      0.00         inf   \n",
       "6                  1.0      0.6        1.00  1.00      0.00         inf   \n",
       "7                  0.6      0.6        0.75  1.25      0.12         1.6   \n",
       "8                  0.8      0.6        1.00  1.25      0.12         inf   \n",
       "9                  1.0      0.6        1.00  1.00      0.00         inf   \n",
       "10                 0.6      0.6        0.75  1.25      0.12         1.6   \n",
       "11                 0.8      0.6        1.00  1.25      0.12         inf   \n",
       "\n",
       "    zhangs_metric  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             1.0  \n",
       "3             0.5  \n",
       "4             0.0  \n",
       "5             0.0  \n",
       "6             0.0  \n",
       "7             1.0  \n",
       "8             0.5  \n",
       "9             0.0  \n",
       "10            1.0  \n",
       "11            0.5  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "res = association_rules(frequent_itemsets, metric= \"confidence\", min_threshold = 0.7)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cec600e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>(Onion)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Onion)</td>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Milk)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Onion)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Yogurt)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Kidney Beans, Eggs)</td>\n",
       "      <td>(Onion)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Kidney Beans, Onion)</td>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Eggs, Onion)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>(Kidney Beans, Onion)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(Onion)</td>\n",
       "      <td>(Kidney Beans, Eggs)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              antecedents            consequents  support  confidence  lift\n",
       "0          (Kidney Beans)                 (Eggs)      0.8        0.80  1.00\n",
       "1                  (Eggs)         (Kidney Beans)      0.8        1.00  1.00\n",
       "2                  (Eggs)                (Onion)      0.6        0.75  1.25\n",
       "3                 (Onion)                 (Eggs)      0.6        1.00  1.25\n",
       "4                  (Milk)         (Kidney Beans)      0.6        1.00  1.00\n",
       "5                 (Onion)         (Kidney Beans)      0.6        1.00  1.00\n",
       "6                (Yogurt)         (Kidney Beans)      0.6        1.00  1.00\n",
       "7    (Kidney Beans, Eggs)                (Onion)      0.6        0.75  1.25\n",
       "8   (Kidney Beans, Onion)                 (Eggs)      0.6        1.00  1.25\n",
       "9           (Eggs, Onion)         (Kidney Beans)      0.6        1.00  1.00\n",
       "10                 (Eggs)  (Kidney Beans, Onion)      0.6        0.75  1.25\n",
       "11                (Onion)   (Kidney Beans, Eggs)      0.6        1.00  1.25"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1 = res[['antecedents','consequents','support','confidence','lift']]\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2a135e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Onion)</td>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Milk)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Onion)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Yogurt)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Kidney Beans, Onion)</td>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Eggs, Onion)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(Onion)</td>\n",
       "      <td>(Kidney Beans, Eggs)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              antecedents           consequents  support  confidence  lift\n",
       "1                  (Eggs)        (Kidney Beans)      0.8         1.0  1.00\n",
       "3                 (Onion)                (Eggs)      0.6         1.0  1.25\n",
       "4                  (Milk)        (Kidney Beans)      0.6         1.0  1.00\n",
       "5                 (Onion)        (Kidney Beans)      0.6         1.0  1.00\n",
       "6                (Yogurt)        (Kidney Beans)      0.6         1.0  1.00\n",
       "8   (Kidney Beans, Onion)                (Eggs)      0.6         1.0  1.25\n",
       "9           (Eggs, Onion)        (Kidney Beans)      0.6         1.0  1.00\n",
       "11                (Onion)  (Kidney Beans, Eggs)      0.6         1.0  1.25"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = res1[res1['confidence'] >= 1]\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aae765d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c947cacb",
   "metadata": {},
   "source": [
    "### **Name some limitations of K-means clustering?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d1caf",
   "metadata": {},
   "source": [
    "K-means clustering, while a popular and widely used algorithm, does have certain limitations. Here are some common limitations of K-means clustering:\n",
    "\n",
    "Number of clusters (k) needs to be known in advance: K-means requires the user to specify the number of clusters before running the algorithm. Determining the optimal number of clusters can be challenging, especially when working with complex or high-dimensional datasets.\n",
    "\n",
    "Sensitive to initial centroid selection: K-means is sensitive to the initial placement of cluster centroids. Different initializations can lead to different results, and there is no guarantee that the algorithm will converge to the global optimum. Multiple runs with different initializations can help mitigate this issue but come at the cost of increased computational complexity.\n",
    "\n",
    "Assumes spherical clusters of equal size: K-means assumes that the clusters are spherical, isotropic, and of equal size. In reality, the clusters may have different shapes, densities, or sizes, leading to suboptimal results. K-means struggles with capturing clusters with irregular shapes or elongated structures.\n",
    "\n",
    "Outliers can significantly affect results: K-means is sensitive to outliers in the dataset. Even a single outlier can significantly distort the cluster centers and boundaries, impacting the overall clustering performance. Preprocessing steps like outlier detection or data normalization may be required to mitigate this problem.\n",
    "\n",
    "May converge to local optima: K-means optimization is based on minimizing the within-cluster sum of squares. However, it is possible for the algorithm to converge to a locally optimal solution rather than the global optimum. This limitation can be addressed through multiple random restarts or by using more advanced initialization techniques.\n",
    "\n",
    "Requires numerical input features: K-means works well with numerical feature vectors. It calculates distances and means based on numeric values. Categorical or textual data need to be preprocessed into numerical representations before applying K-means.\n",
    "\n",
    "Does not handle missing data: K-means cannot handle missing values in the dataset. Missing data needs to be addressed before running the algorithm, either through imputation or by removing instances with missing values.\n",
    "\n",
    "Can be computationally expensive: As the number of samples and dimensions in the dataset increases, the computational cost of K-means can become significant. It may struggle with large-scale datasets due to memory or processing power limitations.\n",
    "\n",
    "It's important to consider these limitations while using K-means clustering and explore alternative algorithms or techniques if they better suit your specific data and requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42972e73",
   "metadata": {},
   "source": [
    "### Explain how Mean-shift clustering works?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68306319",
   "metadata": {},
   "source": [
    "Mean-shift clustering is a popular unsupervised machine learning algorithm used for clustering data points into groups or clusters. It is a density-based clustering algorithm that iteratively shifts the data points towards the higher density regions of the dataset.\n",
    "\n",
    "Here's how Mean-shift clustering works:\n",
    "\n",
    "Data Point Representation: Each data point in the dataset is represented as a feature vector in an n-dimensional space.\n",
    "\n",
    "Kernel Function: A kernel function is defined, which measures the similarity between two data points based on their feature vectors. The most commonly used kernel function is the Gaussian kernel.\n",
    "\n",
    "Initialization: Initially, all data points are considered as potential cluster centers.\n",
    "\n",
    "Shifting Process: For each data point, a mean shift operation is performed iteratively until convergence. The mean shift operation involves two steps:\n",
    "\n",
    "a. Calculation of the mean shift vector: For a given data point, the mean shift vector is calculated as the weighted average of the difference vectors between the data point and its neighboring points. The weighting is done using the kernel function, giving more importance to nearby points.\n",
    "\n",
    "b. Update of data point position: The data point is shifted towards the direction of the mean shift vector, updating its position.\n",
    "\n",
    "Convergence: The shifting process continues until convergence is achieved, which happens when the data points no longer move significantly or when a predetermined number of iterations is reached.\n",
    "\n",
    "Cluster Assignment: After convergence, the final positions of the data points determine the cluster assignments. Points located close to each other are assigned to the same cluster.\n",
    "\n",
    "Post-processing: Optionally, post-processing steps such as merging similar clusters or removing outliers can be applied.\n",
    "\n",
    "Mean-shift clustering has several advantages. It does not require specifying the number of clusters in advance, and it can automatically detect clusters of different shapes and sizes. However, it can be computationally expensive for large datasets and sensitive to the selection of the kernel bandwidth parameter.\n",
    "\n",
    "Overall, Mean-shift clustering is a powerful and flexible algorithm for clustering data points based on their density, making it useful in various applications such as image segmentation, object tracking, and customer segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd8d1b2",
   "metadata": {},
   "source": [
    "### Explain DBSAN algorithm  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d863452d",
   "metadata": {},
   "source": [
    "(Density-Based Spatial Clustering of Applications with Noise) is a popular density-based clustering algorithm used to group data points based on their density in the feature space. It is particularly effective in identifying clusters of arbitrary shapes and handling outliers.\n",
    "\n",
    "Here's how the DBSCAN algorithm works:\n",
    "\n",
    "Parameter Definition: The DBSCAN algorithm requires two parameters to be set:\n",
    "\n",
    "Epsilon (ε): It defines the radius within which neighboring points are considered as part of the same neighborhood.\n",
    "Minimum Points (MinPts): It specifies the minimum number of points required to form a dense region or cluster.\n",
    "Core Points and Neighborhoods: Each data point in the dataset is classified as either a core point, a border point, or a noise point (outlier).\n",
    "\n",
    "Core Point: A data point is considered a core point if it has at least MinPts data points (including itself) within its ε-neighborhood.\n",
    "Border Point: A data point is considered a border point if it has fewer than MinPts data points within its ε-neighborhood but falls within the ε-neighborhood of a core point.\n",
    "Noise Point: A data point is considered a noise point if it is neither a core point nor a border point.\n",
    "Cluster Formation: Starting from an unvisited data point, the algorithm expands a cluster by visiting its ε-neighborhood. The following steps are performed:\n",
    "\n",
    "If the data point is a core point, a new cluster is created, and all reachable points within its ε-neighborhood are added to the cluster.\n",
    "If the data point is a border point, it is assigned to a nearby cluster.\n",
    "If the data point is a noise point, it remains unassigned.\n",
    "Density Connectivity: Clusters are formed by connecting core points and linking them through density connectivity. This process continues until all data points have been visited.\n",
    "\n",
    "Outlier Detection: Noise points (outliers) that do not belong to any cluster are identified during the clustering process.\n",
    "\n",
    "DBSCAN has several advantages over other clustering algorithms:\n",
    "\n",
    "It can discover clusters of arbitrary shapes and sizes.\n",
    "It is robust to outliers and noise in the dataset.\n",
    "It does not require specifying the number of clusters in advance.\n",
    "However, DBSCAN also has some limitations:\n",
    "\n",
    "It requires setting appropriate values for ε and MinPts parameters, which can be challenging in certain cases.\n",
    "It may struggle with datasets of varying densities or when clusters have significantly different densities.\n",
    "Overall, DBSCAN is a powerful density-based clustering algorithm that is widely used in various fields, including spatial data analysis, image processing, and anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a68baca",
   "metadata": {},
   "source": [
    "### Explain hierarchical clustering?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd0515a",
   "metadata": {},
   "source": [
    "Hierarchical clustering is a popular clustering algorithm used to group data points into nested clusters based on their similarities. It forms a hierarchical structure by iteratively merging or splitting clusters, creating a tree-like structure known as a dendrogram.\n",
    "\n",
    "Here's how the hierarchical clustering algorithm works:\n",
    "\n",
    "Data Point Representation: Each data point in the dataset is represented as a feature vector in an n-dimensional space.\n",
    "\n",
    "Similarity Measurement: A similarity or dissimilarity measure (such as Euclidean distance or correlation) is defined to quantify the similarity between pairs of data points. The choice of similarity measure depends on the nature of the data.\n",
    "\n",
    "Initialization: Initially, each data point is considered as an individual cluster.\n",
    "\n",
    "Cluster Similarity Calculation: The similarity between clusters needs to be computed to determine which clusters are more similar and should be merged together. There are two commonly used approaches for calculating the similarity between clusters:\n",
    "\n",
    "a. Single Linkage: The similarity between two clusters is determined by the minimum similarity value between any pair of data points from the two clusters.\n",
    "\n",
    "b. Complete Linkage: The similarity between two clusters is determined by the maximum similarity value between any pair of data points from the two clusters.\n",
    "\n",
    "Other linkage methods, such as average linkage or Ward's linkage, can also be used depending on specific requirements.\n",
    "\n",
    "Merge or Split Process: The clustering algorithm proceeds by iteratively merging or splitting clusters based on their similarity.\n",
    "\n",
    "a. Agglomerative Hierarchical Clustering (Bottom-Up): In the agglomerative approach, the algorithm starts with each data point as an individual cluster and then merges the two most similar clusters at each step. This process continues until all data points belong to a single cluster.\n",
    "\n",
    "b. Divisive Hierarchical Clustering (Top-Down): In the divisive approach, the algorithm starts with all data points belonging to a single cluster and then recursively splits the clusters into smaller subclusters until each data point is in its own cluster.\n",
    "\n",
    "Dendrogram Construction: As clusters are merged or split, a dendrogram is constructed to represent the hierarchy of clusters. The dendrogram visually illustrates the order in which clusters were merged or split and can be used to determine the number of desired clusters based on the desired level of similarity.\n",
    "\n",
    "Cluster Assignment: Finally, the desired level of similarity (determined from the dendrogram) is chosen, and the data points are assigned to their respective clusters.\n",
    "\n",
    "Hierarchical clustering has several advantages:\n",
    "\n",
    "It does not require specifying the number of clusters in advance.\n",
    "It provides a hierarchical structure that allows for analysis at different levels of granularity.\n",
    "It can handle data with varying shapes and sizes of clusters.\n",
    "However, hierarchical clustering also has some limitations:\n",
    "\n",
    "It can be computationally expensive for large datasets.\n",
    "Once a decision to merge or split clusters is made, it cannot be undone.\n",
    "The choice of linkage method and similarity measure can significantly impact the results.\n",
    "Overall, hierarchical clustering is a flexible and interpretable clustering algorithm that is widely used in various fields, such as biology, social sciences, and market segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df8866f",
   "metadata": {},
   "source": [
    "### Explain single- linkage, complete- linkage, average- linkage and centroid linkage  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea131f8",
   "metadata": {},
   "source": [
    "Certainly! In hierarchical clustering, different linkage methods are used to measure the similarity or dissimilarity between clusters. Here's an explanation of four common linkage methods: single-linkage, complete-linkage, average-linkage, and centroid linkage.\n",
    "\n",
    "Single Linkage:\n",
    "\n",
    "Also known as nearest-neighbor linkage or minimum linkage.\n",
    "It measures the similarity between two clusters by considering the minimum distance between any pair of data points, one from each cluster.\n",
    "In other words, it evaluates the similarity based on the closest data points between the clusters.\n",
    "Single linkage tends to form long, elongated clusters and is sensitive to noise and outliers.\n",
    "Complete Linkage:\n",
    "\n",
    "Also known as furthest-neighbor linkage or maximum linkage.\n",
    "It measures the similarity between two clusters by considering the maximum distance between any pair of data points, one from each cluster.\n",
    "In other words, it evaluates the similarity based on the farthest data points between the clusters.\n",
    "Complete linkage tends to form compact, spherical clusters and is less sensitive to noise and outliers than single linkage.\n",
    "Average Linkage:\n",
    "\n",
    "It measures the similarity between two clusters by considering the average distance between all pairs of data points, one from each cluster.\n",
    "In other words, it evaluates the similarity based on the average distance of all data point pairs between the clusters.\n",
    "Average linkage produces balanced clusters and is less affected by noise and outliers compared to single linkage.\n",
    "Centroid Linkage:\n",
    "\n",
    "It measures the similarity between two clusters by considering the distance between the centroids (mean feature vectors) of the clusters.\n",
    "In other words, it evaluates the similarity based on the distance between the cluster centers.\n",
    "Centroid linkage can handle clusters of varying shapes and sizes but may be sensitive to outliers.\n",
    "Each linkage method has its own characteristics and can yield different results when applied to the same dataset. The choice of linkage method depends on the nature of the data and the desired properties of the clusters, such as compactness, elongation, or sensitivity to outliers.\n",
    "\n",
    "It's worth noting that there are other linkage methods available beyond these four, such as Ward's linkage (based on minimizing the sum of squared differences within clusters) or median linkage (using the median distance between all pairs of data points). These alternative methods provide additional flexibility and cater to specific requirements in clustering analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02affb1",
   "metadata": {},
   "source": [
    "### **1-Write a python program to find the 1000th prime number.\n",
    "A prime number is a natural number greater than 1 that has no positive\n",
    "divisors other than 1 and itself. By Euclid's theorem, there are an infinite\n",
    "number of prime numbers. Subsets of the prime numbers may be generated\n",
    "with various formulas for primes. The first twenty prime numbers are: 2, 3, 5, 7. 11. 13, 17. 19, 23, 29, 31. 37, 41. 43, 47, 53, 59, 61, 67, 71.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf4b3f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227, 229, 233, 239, 241, 251, 257, 263, 269, 271, 277, 281, 283, 293, 307, 311, 313, 317, 331, 337, 347, 349, 353, 359, 367, 373, 379, 383, 389, 397, 401, 409, 419, 421, 431, 433, 439, 443, 449, 457, 461, 463, 467, 479, 487, 491, 499, 503, 509, 521, 523, 541, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_prime_number(num):\n",
    "    \n",
    "    prime_count=0\n",
    "    prime=0\n",
    "    count=2\n",
    "    is_prime=False\n",
    "    while prime_count < num:\n",
    "        is_prime=True\n",
    "        for i in range(2,count-1):\n",
    "            if(count%i==0):\n",
    "                is_prime=False\n",
    "        if(is_prime):\n",
    "            print(count, end=\", \")\n",
    "            prime_count+=1\n",
    "\n",
    "                \n",
    "        count+=1\n",
    "                \n",
    "        \n",
    "    \n",
    "    return prime\n",
    "\n",
    "find_prime_number(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad73b47",
   "metadata": {},
   "source": [
    "### **2-Write a Python program to find the product xyz.\n",
    "A Pythagorean triple consists of three positive integers a, b, and c, such that a2 + b2 = c2. Such a triple is commonly written (a, b, c), and a well-known\n",
    "example is (3, 4, 5). There exists exactly one Pythagorean triplet for which x+\n",
    "y+z=1000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "700fff5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 375 425\n"
     ]
    }
   ],
   "source": [
    "# using pythagoras theorem, the sum of 3 elements shuld be 1000.\n",
    "\n",
    "# def find_product( target):\n",
    "#     temp=0\n",
    "#     #limit = math.sqrt(target)\n",
    "#     while(temp!=target):\n",
    "#         temp= a**2 + b**2 + c**2\n",
    "#     print(\"{}^2 + {}^2 + {}^2 =1000\".format(a,b,c))\n",
    "        \n",
    "# find_product(target)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_triple(sum_val):\n",
    "    for a in range(1,sum_val):\n",
    "        for b in range(a+1, sum_val):\n",
    "            c = sum_val - a - b\n",
    "            if c > 0 and c**2 == b**2 + a**2:\n",
    "                print(a,b,c)\n",
    "find_triple(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e520f92",
   "metadata": {},
   "source": [
    "# Understanding Association Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a8d99f",
   "metadata": {},
   "source": [
    "Association rule is a concept in data mining and analytics that identifies relationships or patterns between items in a dataset. It is used to discover associations or correlations between different items based on their co-occurrence in transactions or events.\n",
    "\n",
    "In the given example, \"Bread => Butter,\" it suggests that there is a high likelihood of customers purchasing butter when they buy bread. This association implies that these two items are frequently bought together, and the presence of one item (bread) can be used to predict or influence the presence of the other item (butter). The arrow symbol (=>) represents the implication or relationship between the items.\n",
    "\n",
    "Similarly, the second example, \"buys {onions, potatoes} => buys {tomatoes},\" indicates that customers who purchase onions and potatoes are likely to buy tomatoes as well. This association rule reveals that there is a strong connection between the three items, and the presence of onions and potatoes can be indicative of the presence of tomatoes.\n",
    "\n",
    "Association rules are commonly used in market basket analysis, where they help businesses understand customer buying patterns and make strategic decisions related to product placement, promotions, and cross-selling. By identifying these associations, businesses can optimize their offerings, improve customer satisfaction, and boost sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c08705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
